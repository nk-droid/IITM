{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIu321o7Wn1v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SxAeJEE1V3cM"
      },
      "source": [
        "### PRACTICE ASSIGNMENT"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "B4URYD4-V84L"
      },
      "source": [
        "Q1. Write a function `compute_score(X_train, y_train, X_test, y_test)`\n",
        " to do the following on the `Iris` dataset-\n",
        "\n",
        "Write your code keeping in mind:\n",
        "\n",
        "Split the `Iris` dataset into `train` and `test` set with $70:30$ ratio\n",
        "Import `svm.SVC` as *model*, kernel as *rbf*, regularization parameter as $20$ and gamma as *auto*\n",
        "\n",
        "Take `random_state=42`.\n",
        "\n",
        "Train the model using training data and predict the computed model's score using test data.\n",
        "  \n",
        "Which of the following options is the computed score?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOhmLEMDXAJm"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s17Teu43VutU"
      },
      "outputs": [],
      "source": [
        "def compute_score(X_train, y_train, X_test, y_test) :\n",
        "  svc = SVC(kernel = 'rbf', C = 20, gamma = 'auto', random_state = 42)\n",
        "  svc.fit(X_train, y_train)\n",
        "  # y_test_pred = svc.predict(X_test)\n",
        "  return svc.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBeeEyguXKiq",
        "outputId": "1c22f1f5-d098-426d-a3cb-7a60802c4f31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size = .3, random_state = 42)\n",
        "compute_score(X_train, y_train, X_test, y_test)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NNbyxkP6cM-4"
      },
      "source": [
        "Q2. In *Question 1*, apply a `pipeline` containing a `MinMaxScaler()` function called scaler and a `svm.svc()` called classifier with the parameters : `kernel='linear', decision_function_shape='ovr', C=1, class_weight=None`. Calculate the `precision` value and `f1` score and mark the correct option from the list below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSL8YXvEdCb4"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import precision_score, f1_score, recall_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o065u-fXcftz"
      },
      "outputs": [],
      "source": [
        "def compute_score(X_train, y_train, X_test, y_test) :\n",
        "  svc = SVC(kernel = 'linear', decision_function_shape='ovr', C = 1, gamma = 'auto', class_weight=None, random_state = 42)\n",
        "  model = Pipeline([('scaler', MinMaxScaler()),\n",
        "                       ('classifier', svc)])\n",
        "  model.fit(X_train, y_train)\n",
        "  y_test_pred = model.predict(X_test)\n",
        "  return precision_score(y_test, y_test_pred, average = 'weighted'), f1_score(y_test, y_test_pred, average = 'weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LTCBEDzeZZL",
        "outputId": "5577c8de-0455-4faa-e728-aec82982c177"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1.0, 1.0)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_score(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yTaCMj2cj6Kd"
      },
      "source": [
        "Q3. Import the `iris` dataset and drop the rows where `class=Iris-versicolor`. Apply a `pipeline` containing a `MinMaxScaler()` function called scaler and a `svm.svc()` called classifier. Split the `iris` dataset into 50:50 ratio with `random_state=0`. Mark the correct recall value from the given options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvdJRactn3a_"
      },
      "outputs": [],
      "source": [
        "X, y = data.data[:100], data.target[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvHhzjYdqOu1"
      },
      "outputs": [],
      "source": [
        "X_train_, X_test_, y_train_, y_test_ = train_test_split(X, y, test_size = .5, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4pgyImkqYob"
      },
      "outputs": [],
      "source": [
        "def compute_score(X_train, y_train, X_test, y_test) :\n",
        "  svc = SVC(kernel = 'linear', decision_function_shape='ovr', C = 1, gamma = 'auto', class_weight=None, random_state = 42)\n",
        "  model = Pipeline([('scaler', MinMaxScaler()),\n",
        "                       ('classifier', svc)])\n",
        "  model.fit(X_train, y_train)\n",
        "  y_test_pred = model.predict(X_test)\n",
        "  return recall_score(y_test, y_test_pred, average = 'weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ol7U-CePqaPT",
        "outputId": "f80dbc07-f55a-4d12-f972-54787b3a04c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_score(X_train_, y_train_, X_test_, y_test_)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "w-vCC1bSqtb2"
      },
      "source": [
        "Q4. Write the function `compute_score(X_train, y_train, X_test, y_test)`\n",
        " to do the following on the `Iris` dataset-\n",
        "\n",
        "Write your code keeping in mind:\n",
        "\n",
        "Split the `Iris` dataset into train and test set with 70:30 ratio and `random_state=42`\n",
        "\n",
        "Import `sklearn.svm.LinearSVC` as *model*\n",
        "\n",
        "Consider loss function `loss=hinge`, `random_state=42` and `penalty=l2`\n",
        "\n",
        "Train the *model* and mark the computed score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDJuJpqLrQM2"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19eXofPCrreW"
      },
      "outputs": [],
      "source": [
        "def compute_score(X_train, y_train, X_test, y_test) :\n",
        "  svm = LinearSVC(loss = 'hinge', random_state = 42, penalty = 'l2')\n",
        "  svm.fit(X_train, y_train)\n",
        "  return svm.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg0r2kvwsM2I",
        "outputId": "2414b585-bbc9-4d59-eba9-9e17914b58ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_score(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fdJg_3lTuOz6"
      },
      "source": [
        "Q5. Write a function `hyperparameter_search` which accepts the `kernel` and `regularization parameter` as inputs and returns the `avg_score` of the models with the below mentioned hyperparameters.\n",
        "\n",
        "Split the `Iris` dataset into train and test set with $70:30$ ratio\n",
        "`kernels = ['linear', 'rbf']`, Regularization `C = [5, 10,100]`, `Cross Validation = 10`, `random_state=42`.\n",
        "\n",
        "Which of the following options give the `accuracy_score` for the `iris` dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g93vYihMcG9O"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0uKi-8YuQOq"
      },
      "outputs": [],
      "source": [
        "def hyperparameter_search(kernel, C) :\n",
        "  data = load_iris()\n",
        "  X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size = .3, random_state = 42)\n",
        "  params = {'kernel': kernel, 'C': C}\n",
        "  svm = SVC(gamma = 'auto', random_state = 42)\n",
        "  gscv = GridSearchCV(svm, param_grid=params, cv = 10)\n",
        "  gscv.fit(X_train, y_train)\n",
        "  y_test_pred = gscv.predict(X_test)\n",
        "  return accuracy_score(y_test, y_test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtmsuKaXcLHa",
        "outputId": "9c8c97db-046c-4377-c76b-4c7d89c989f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kernels = ('linear' , 'rbf')\n",
        "C = [5, 10, 100]\n",
        "hyperparameter_search(kernels, C)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KzhNd2_PuQyZ"
      },
      "source": [
        "### GRADED ASSIGNMENT"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bCd2Fyb3ueSL"
      },
      "source": [
        "Q1. Write a function `compute_GridSearchCV` which accepts the `Kernel` and `regularization parameters` as inputs and returns the `Mean cross-validated score` of the best_estimator, denoted with `best_score_` of the models with the below mentioned hyperparameters:\n",
        "\n",
        "Split the `Iris` dataset into train and test set with $70:30$ ratio\n",
        "\n",
        "Import `svm.SVC` as *model*, `kernels = ['linear' , 'rbf']`, `Regularization = [1,15,25]`, `gamma = 'auto'`, `Cross Validation = 4`, `random_state=0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-ylgjP7WE7l"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc3b7bpeuiNX"
      },
      "outputs": [],
      "source": [
        "def compute_GridSearchCV(kernel, C) :\n",
        "  data = load_iris()\n",
        "  X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size = .3, random_state = 0)\n",
        "  params = {'kernel': kernel, 'C': C}\n",
        "  svm = SVC(gamma = 'auto', random_state = 0)\n",
        "  gscv = GridSearchCV(svm, param_grid=params, cv = 4)\n",
        "  gscv.fit(X_train, y_train)\n",
        "  return gscv.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DildLyBeWj-I",
        "outputId": "4a6fda33-acc5-492a-8f91-8e4d032f8e67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9807692307692308"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kernels = ('linear' , 'rbf')\n",
        "C = [1,15,25]\n",
        "compute_GridSearchCV(kernels, C)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ihkfJGu2uiiz"
      },
      "source": [
        "**(Consider the statement for Q.NO 2 and Q.NO 3)**\n",
        "\n",
        "Read the instructions given below to answer the two questions given below."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WyrK-tvLup3n"
      },
      "source": [
        "Split the *Social_Network_Ads*\n",
        " dataset (https://drive.google.com/file/d/1qUa1GlG4X4ZY_4E0e7jPR-z7AG7NIDbE/view?usp=sharing) into training and test set in 75:25 ratio.\n",
        "\n",
        "Fit and transform the train and test set of the feature matrix by applying `StandardScaler` transformer.\n",
        "\n",
        "Fit a linear SVM (with `random_state = 0` and `linear kernel`) to training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFX4Qjpp0_lr"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjiWZG2evFJa"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Assignment_files/MLP/Social_Network_Ads.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BsKtXTZvVlZ",
        "outputId": "e7503679-4840-4490-bac1-3adea1e51896"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SVC(kernel='linear', random_state=0)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size = .25, random_state = 0)\n",
        "\n",
        "svm = SVC(kernel = 'linear', random_state = 0)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "svm.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "U9-0eraR2R5K"
      },
      "source": [
        "Q2. The predicted data returns an accuracy_score on test data. Which of the following option represents the calculated accuracy_score?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq8AGoCn2TkM",
        "outputId": "b7312a7b-332a-4d1b-975e-6c6a12baabae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.88"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test_pred = svm.predict(X_test_scaled)\n",
        "accuracy_score(y_test, y_test_pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pchheJkf4I4j"
      },
      "source": [
        "Q3. Calculate the confusion matrix obtained from the above predicted data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI_Mv_9k4MIH",
        "outputId": "8292a5c7-b0eb-4ed0-e01a-64f45d482652"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[63,  5],\n",
              "       [ 7, 25]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_test_pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rQtxCZq75nNr"
      },
      "source": [
        "**(Consider the statement for Q.NO 4 and Q.NO 5)**\n",
        "\n",
        "Read the instructions given below to answer the two questions given below."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DTUKnUwX5MVM"
      },
      "source": [
        "From the `MNIST` dataset, consider the first $20,000$ data samples as training data and the next $5,000$ data samples as test data. Fit a `pipeline` with `MinMaxScaler` and a *classifier* with `SVC`, `linear kernel`, `one vs rest decision_function_shape` and `class_weight = None`to this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LG_bo-x5hyh"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "data = fetch_openml('mnist_784', version = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4sb5Gzo6RG-"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = data.data[:20000], data.data[20000:25000], data.target[:20000], data.target[20000:25000]\n",
        "\n",
        "model = Pipeline([('scaler', MinMaxScaler()),\n",
        "                  ('classifier', SVC(kernel = 'linear', decision_function_shape = 'ovr', class_weight = None))])\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_test_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZggvVIm_NMr",
        "outputId": "45bc46ff-a844-4d39-b23a-938873480088"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((20000, 784), (5000, 784))"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9cV8zt8x9Bx_"
      },
      "source": [
        "Q4. What is the sum of the main diagonal elements of the confusion matrix?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTcHyfsG9OB8",
        "outputId": "ce43f445-071e-4693-d65b-340247195838"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4623"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix(y_test, y_test_pred).trace()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NsY7WYH1_vwk"
      },
      "source": [
        "Q5. Which of the following are the correct values of precision, recall and f1_Score?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvhXtUTg_wE_",
        "outputId": "f87cc2b6-9d84-44cb-ae28-118977e11ba7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.9245834577056025 Recall: 0.9246 f1_Score: 0.9242341822537996\n"
          ]
        }
      ],
      "source": [
        "print(\"Precision:\", precision_score(y_test, y_test_pred, average='weighted'), \"Recall:\", recall_score(y_test, y_test_pred, average='weighted'), \"f1_Score:\", f1_score(y_test, y_test_pred, average='weighted'))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IhhjWAZNDtty"
      },
      "source": [
        "Q6. Consider the `MNIST` dataset, split it into training and test set in $50:50$ ratio with `random_state = 42`. Fit a `SVM` model using `pipeline` with `StandardScalar`, `SVM` classifier `kernel='poly'` and `degree = 3`, `decision_function_shape='ovr'` and `class_weight='balanced'`, `C=10`. Train the model on training data, and make predictions for test data. Generate the Classification report and choose the correct value for weighted avg of `f1_score`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aopDyhJEKzG"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size = 0.5, random_state = 42)\n",
        "\n",
        "model = Pipeline([('scaler', StandardScaler()),\n",
        "                  ('classifier', SVC(kernel = 'poly', degree = 3, decision_function_shape = 'ovr', class_weight = 'balanced', C = 10))])\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_test_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQqX1O7hFPXd",
        "outputId": "77235cea-1747-41a6-a85f-b65e2429d0f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99      3463\n",
            "           1       0.99      0.99      0.99      3927\n",
            "           2       0.96      0.97      0.96      3520\n",
            "           3       0.98      0.96      0.97      3551\n",
            "           4       0.96      0.98      0.97      3333\n",
            "           5       0.97      0.97      0.97      3144\n",
            "           6       0.98      0.98      0.98      3490\n",
            "           7       0.98      0.97      0.97      3718\n",
            "           8       0.96      0.96      0.96      3344\n",
            "           9       0.96      0.96      0.96      3510\n",
            "\n",
            "    accuracy                           0.97     35000\n",
            "   macro avg       0.97      0.97      0.97     35000\n",
            "weighted avg       0.97      0.97      0.97     35000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JQqK-XuvHpmE"
      },
      "source": [
        "Q7. Write the function `compute_score(X_train, y_train, X_test, y_test)` to do the following on the `Iris` dataset-\n",
        "\n",
        "Write your code keeping in mind:\n",
        "\n",
        "Split the `Iris` dataset into `train` and `test` set with $70:30$ ratio\n",
        "\n",
        "Import `svm.SVC` as *model*, `kernel` as `'poly'`, `regularization parameter` as `10` and `gamma` as `'auto'`\n",
        "\n",
        "Train the *model* and mark the computed score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhZvzotIIIIl",
        "outputId": "a7998715-5e8b-497f-a770-07da1aacc7f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size = 0.3, random_state = 42)\n",
        "\n",
        "model = SVC(kernel = 'poly', C = 10, gamma = 'auto')\n",
        "model.fit(X_train, y_train)\n",
        "model.score(X_test, y_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_VIuC8_bN3qO"
      },
      "source": [
        "Q8. Write the function `compute_score(X_train, y_train, X_test, y_test)` to do the following on the `Iris` dataset-\n",
        "\n",
        "Write your code keeping in mind:\n",
        "\n",
        "Split the `Iris` dataset into train and test set with $70:30$ ratio\n",
        "\n",
        "Import `svm.SVC` as *model*, `kernel` as `'sigmoid'`, `regularization parameter` as `25` and `gamma` as `'auto'`\n",
        "\n",
        "Train the *model* and mark the computed score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P9q4XigOTy2",
        "outputId": "77eecc1d-62ab-4d58-f014-8806782662dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.28888888888888886"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = SVC(kernel = 'sigmoid', C = 25, gamma = 'auto')\n",
        "model.fit(X_train, y_train)\n",
        "model.score(X_test, y_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "awh94uHwOq5d"
      },
      "source": [
        "Q9. Import the `iris` dataset and drop the rows where `class=Iris-setosa`. Apply a `pipeline` containing a `MinMaxScaler()` function called *scaler* and a `svm.svc()` called *classifier*. Split the `iris` dataset into $75:25$ ratio with `random_state=0`. Mark the correct `precision_score`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExSVlJqkPDeC"
      },
      "outputs": [],
      "source": [
        "data = load_iris()\n",
        "X, y = data.data[50:], data.target[50:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oB-NXOcPPUi"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuHyYcDRPLTT"
      },
      "outputs": [],
      "source": [
        "def compute_score(X_train, y_train, X_test, y_test) :\n",
        "  svc = SVC(kernel = 'linear', decision_function_shape='ovr', C = 1, gamma = 'auto', class_weight=None, random_state=0)\n",
        "  model = Pipeline([('scaler', MinMaxScaler()),\n",
        "                       ('classifier', svc)])\n",
        "  model.fit(X_train, y_train)\n",
        "  y_test_pred = model.predict(X_test)\n",
        "  return precision_score(y_test, y_test_pred, average = 'weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aAashOcQH8u",
        "outputId": "98e3e902-2b02-45bd-c1de-12e3a41df279"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.963076923076923"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_score(X_train, y_train, X_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
